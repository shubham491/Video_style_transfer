{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qP0QbSHM9e0K"
   },
   "outputs": [],
   "source": [
    "import vgg, pdb, time\n",
    "import tensorflow as tf, numpy as np, os\n",
    "import transform\n",
    "import scipy.misc, numpy as np, os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELCtXYg69ii6"
   },
   "outputs": [],
   "source": [
    "def save_img(out_path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(out_path, img)\n",
    "\n",
    "def scale_img(style_path, style_scale):\n",
    "    scale = float(style_scale)\n",
    "    o0, o1, o2 = scipy.misc.imread(style_path, mode='RGB').shape\n",
    "    scale = float(style_scale)\n",
    "    new_shape = (int(o0 * scale), int(o1 * scale), o2)\n",
    "    style_target = _get_img(style_path, img_size=new_shape)\n",
    "    return style_target\n",
    "\n",
    "def get_img(src, img_size=False):\n",
    "   img = scipy.misc.imread(src, mode='RGB') # misc.imresize(, (256, 256, 3))\n",
    "   if not (len(img.shape) == 3 and img.shape[2] == 3):\n",
    "       img = np.dstack((img,img,img))\n",
    "   if img_size != False:\n",
    "       img = scipy.misc.imresize(img, img_size)\n",
    "   return img\n",
    "\n",
    "def exists(p, msg):\n",
    "    assert os.path.exists(p), msg\n",
    "\n",
    "def list_files(in_path):\n",
    "    files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(in_path):\n",
    "        files.extend(filenames)\n",
    "        break\n",
    "\n",
    "    return files\n",
    "def _tensor_size(tensor):\n",
    "    from operator import mul\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()[1:]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEvLZRcN9s42"
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')\n",
    "CONTENT_LAYER = 'relu4_2'\n",
    "DEVICES = 'CUDA_VISIBLE_DEVICES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uwtbKCy-jk_"
   },
   "outputs": [],
   "source": [
    "def optimize(content_targets, style_target, content_weight, style_weight,\n",
    "             tv_weight, vgg_path, epochs=2, print_iterations=1000,\n",
    "             batch_size=4, save_path='saver/fns.ckpt',\n",
    "             learning_rate=1e-3):\n",
    "    mod = len(content_targets) % batch_size\n",
    "    if mod > 0:\n",
    "        print(\"Train set has been trimmed slightly..\")\n",
    "        content_targets = content_targets[:-mod] \n",
    "\n",
    "    style_features = {}\n",
    "\n",
    "    batch_shape = (batch_size,256,256,3)\n",
    "    style_shape = (1,) + style_target.shape\n",
    "    print(style_shape)\n",
    "\n",
    "    # precompute style features\n",
    "    with tf.Graph().as_default(), tf.device('/cpu:0'), tf.Session() as sess:\n",
    "        style_image = tf.placeholder(tf.float32, shape=style_shape, name='style_image')\n",
    "        style_image_pre = vgg.preprocess(style_image)\n",
    "        print(vgg_path)\n",
    "        net = vgg.net(vgg_path, style_image_pre)\n",
    "        style_pre = np.array([style_target])\n",
    "        for layer in STYLE_LAYERS:\n",
    "            features = net[layer].eval(feed_dict={style_image:style_pre})\n",
    "            features = np.reshape(features, (-1, features.shape[3]))\n",
    "            gram = np.matmul(features.T, features) / features.size\n",
    "            style_features[layer] = gram\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        X_content = tf.placeholder(tf.float32, shape=batch_shape, name=\"X_content\")\n",
    "        X_pre = vgg.preprocess(X_content)\n",
    "\n",
    "        # precompute content features\n",
    "        content_features = {}\n",
    "        content_net = vgg.net(vgg_path, X_pre)\n",
    "        content_features[CONTENT_LAYER] = content_net[CONTENT_LAYER]\n",
    "\n",
    "        preds = transform.net(X_content/255.0)\n",
    "        preds_pre = vgg.preprocess(preds)\n",
    "\n",
    "        net = vgg.net(vgg_path, preds_pre)\n",
    "\n",
    "        content_size = _tensor_size(content_features[CONTENT_LAYER])*batch_size\n",
    "        assert _tensor_size(content_features[CONTENT_LAYER]) == _tensor_size(net[CONTENT_LAYER])\n",
    "        content_loss = content_weight * (2 * tf.nn.l2_loss(\n",
    "            net[CONTENT_LAYER] - content_features[CONTENT_LAYER]) / content_size\n",
    "        )\n",
    "\n",
    "        style_losses = []\n",
    "        for style_layer in STYLE_LAYERS:\n",
    "            layer = net[style_layer]\n",
    "            bs, height, width, filters = [i.value for i in layer.get_shape()]\n",
    "            size = height * width * filters\n",
    "            feats = tf.reshape(layer, (bs, height * width, filters))\n",
    "            feats_T = tf.transpose(feats, perm=[0,2,1])\n",
    "            grams = tf.matmul(feats_T, feats) / size\n",
    "            style_gram = style_features[style_layer]\n",
    "            style_losses.append(2 * tf.nn.l2_loss(grams - style_gram)/style_gram.size)\n",
    "\n",
    "        style_loss = style_weight * reduce(tf.add, style_losses) / batch_size\n",
    "\n",
    "        # total variation denoising\n",
    "        tv_y_size = _tensor_size(preds[:,1:,:,:])\n",
    "        tv_x_size = _tensor_size(preds[:,:,1:,:])\n",
    "        y_tv = tf.nn.l2_loss(preds[:,1:,:,:] - preds[:,:batch_shape[1]-1,:,:])\n",
    "        x_tv = tf.nn.l2_loss(preds[:,:,1:,:] - preds[:,:,:batch_shape[2]-1,:])\n",
    "        tv_loss = tv_weight*2*(x_tv/tv_x_size + y_tv/tv_y_size)/batch_size\n",
    "\n",
    "        loss = content_loss + style_loss + tv_loss\n",
    "        print(loss)\n",
    "        # overall loss\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        import random\n",
    "        uid = random.randint(1, 100)\n",
    "        print(\"UID: %s\" % uid)\n",
    "        for epoch in range(epochs):\n",
    "            print(epoch)\n",
    "            num_examples = len(content_targets)\n",
    "            iterations = 0\n",
    "            while iterations * batch_size < num_examples:\n",
    "                start_time = time.time()\n",
    "                curr = iterations * batch_size\n",
    "                step = curr + batch_size\n",
    "                X_batch = np.zeros(batch_shape, dtype=np.float32)\n",
    "                for j, img_p in enumerate(content_targets[curr:step]):\n",
    "                    X_batch[j] = get_img(img_p, (256,256,3)).astype(np.float32)\n",
    "\n",
    "                iterations += 1\n",
    "                print(\"assert\")\n",
    "                assert X_batch.shape[0] == batch_size\n",
    "\n",
    "                feed_dict = {\n",
    "                   X_content:X_batch\n",
    "                }\n",
    "\n",
    "                train_step.run(feed_dict=feed_dict)\n",
    "                end_time = time.time()\n",
    "                delta_time = end_time - start_time\n",
    "                print(\"UID: %s, batch time: %s\" % (uid, delta_time))\n",
    "                is_print_iter = int(iterations) % print_iterations == 0\n",
    "                is_last = epoch == epochs - 1 and iterations * batch_size >= num_examples\n",
    "                should_print = is_print_iter or is_last\n",
    "                if should_print:\n",
    "                    to_get = [style_loss, content_loss, tv_loss, loss, preds]\n",
    "                    test_feed_dict = {\n",
    "                    X_content:X_batch\n",
    "                    }\n",
    "                    tup = sess.run(to_get, feed_dict = test_feed_dict)\n",
    "                    _style_loss,_content_loss,_tv_loss,_loss,_preds = tup\n",
    "                    losses = (_style_loss, _content_loss, _tv_loss, _loss)\n",
    "                    saver = tf.train.Saver()\n",
    "                    res = saver.save(sess, save_path)\n",
    "                    yield(_preds, losses, iterations, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btusuPhk_Qzz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import transform, numpy as np, vgg, pdb, os\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x3-3PShNEQLX"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "DEVICE = '/gpu:0'\n",
    "\n",
    "# get img_shape\n",
    "def ffwd(data_in, paths_out, checkpoint_dir, device_t='/gpu:0', batch_size=4):\n",
    "    assert len(paths_out) > 0\n",
    "    is_paths = type(data_in[0]) == str\n",
    "    if is_paths:\n",
    "        assert len(data_in) == len(paths_out)\n",
    "        img_shape = get_img(data_in[0]).shape\n",
    "    else:\n",
    "        assert data_in.size[0] == len(paths_out)\n",
    "        img_shape = X[0].shape\n",
    "\n",
    "    g = tf.Graph()\n",
    "    batch_size = min(len(paths_out), batch_size)\n",
    "    curr_num = 0\n",
    "    soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    soft_config.gpu_options.allow_growth = True\n",
    "    with g.as_default(), g.device(device_t), \\\n",
    "            tf.Session(config=soft_config) as sess:\n",
    "        batch_shape = (batch_size,) + img_shape\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                         name='img_placeholder')\n",
    "\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir(checkpoint_dir):\n",
    "            ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            saver.restore(sess, checkpoint_dir)\n",
    "\n",
    "        num_iters = int(len(paths_out)/batch_size)\n",
    "        for i in range(num_iters):\n",
    "            pos = i * batch_size\n",
    "            curr_batch_out = paths_out[pos:pos+batch_size]\n",
    "            if is_paths:\n",
    "                curr_batch_in = data_in[pos:pos+batch_size]\n",
    "                X = np.zeros(batch_shape, dtype=np.float32)\n",
    "                for j, path_in in enumerate(curr_batch_in):\n",
    "                    img = get_img(path_in)\n",
    "                    assert img.shape == img_shape, \\\n",
    "                        'Images have different dimensions. ' +  \\\n",
    "                        'Resize images or use --allow-different-dimensions.'\n",
    "                    X[j] = img\n",
    "            else:\n",
    "                X = data_in[pos:pos+batch_size]\n",
    "\n",
    "            _preds = sess.run(preds, feed_dict={img_placeholder:X})\n",
    "            for j, path_out in enumerate(curr_batch_out):\n",
    "                save_img(path_out, _preds[j])\n",
    "                \n",
    "        remaining_in = data_in[num_iters*batch_size:]\n",
    "        remaining_out = paths_out[num_iters*batch_size:]\n",
    "    if len(remaining_in) > 0:\n",
    "        ffwd(remaining_in, remaining_out, checkpoint_dir, \n",
    "            device_t=device_t, batch_size=1)\n",
    "\n",
    "def ffwd_to_img(in_path, out_path, checkpoint_dir, device='/cpu:0'):\n",
    "    paths_in, paths_out = [in_path], [out_path]\n",
    "    ffwd(paths_in, paths_out, checkpoint_dir, batch_size=1, device_t=device)\n",
    "\n",
    "def ffwd_different_dimensions(in_path, out_path, checkpoint_dir, \n",
    "            device_t=DEVICE, batch_size=4):\n",
    "    in_path_of_shape = defaultdict(list)\n",
    "    out_path_of_shape = defaultdict(list)\n",
    "    for i in range(len(in_path)):\n",
    "        in_image = in_path[i]\n",
    "        out_image = out_path[i]\n",
    "        shape = \"%dx%dx%d\" % get_img(in_image).shape\n",
    "        in_path_of_shape[shape].append(in_image)\n",
    "        out_path_of_shape[shape].append(out_image)\n",
    "    for shape in in_path_of_shape:\n",
    "        print(('Processing images of shape %s' % shape))\n",
    "        ffwd(in_path_of_shape[shape], out_path_of_shape[shape], \n",
    "            checkpoint_dir, device_t, batch_size)\n",
    "\n",
    "\n",
    "def check_opts(opts):\n",
    "    exists(opts.checkpoint_dir, 'Checkpoint not found!')\n",
    "    exists(opts.in_path, 'In path not found!')\n",
    "    if os.path.isdir(opts.out_path):\n",
    "        exists(opts.out_path, 'out dir not found!')\n",
    "        assert opts.batch_size > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oc25HdWsEpvW"
   },
   "outputs": [],
   "source": [
    "DEVICE = '/gpu:0'\n",
    "FRAC_GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_files(img_dir):\n",
    "    files = list_files(img_dir)\n",
    "    return [os.path.join(img_dir,x) for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DHjRbrHF_nH"
   },
   "outputs": [],
   "source": [
    "def style(styleImg, checkpointDir, vggPath, trainPath, testImg, testResDir, contentWeight, styleWeight, tvWeight, learningRate, checkPointIterations, epochs, batch_size):\n",
    "    style_target = get_img(styleImg)\n",
    "    content_targets = _get_files(trainPath)\n",
    "\n",
    "    kwargs = {\n",
    "        \"epochs\":epochs,\n",
    "        \"print_iterations\":checkPointIterations,\n",
    "        \"batch_size\":batch_size,\n",
    "        \"save_path\":os.path.join(checkpointDir,'fns.ckpt'),\n",
    "        \"learning_rate\":learningRate\n",
    "    }\n",
    "\n",
    "\n",
    "    args = [\n",
    "        content_targets,\n",
    "        style_target,\n",
    "        contentWeight,\n",
    "        styleWeight,\n",
    "        tvWeight,\n",
    "        vggPath\n",
    "    ]\n",
    "\n",
    "    for preds, losses, i, epoch in optimize(*args, **kwargs):\n",
    "        style_loss, content_loss, tv_loss, loss = losses\n",
    "        print('Epoch %d, Iteration: %d, Loss: %s' % (epoch, i, loss))\n",
    "        to_print = (style_loss, content_loss, tv_loss)\n",
    "        print('style: %s, content:%s, tv: %s' % to_print)\n",
    "        preds_path = '%s/%s_%s.png' % (testResDir,epoch,i)\n",
    "        ckpt_dir = os.path.dirname(checkpointDir)\n",
    "        ffwd_to_img(testImg,preds_path,\n",
    "                                     checkpointDir)\n",
    "    ckpt_dir = checkpointDir\n",
    "    # cmd_text = 'python evaluate.py --checkpoint-dir %s ...' % ckpt_dir\n",
    "    print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILXbBhjxdMfv"
   },
   "outputs": [],
   "source": [
    "def passArgument():\n",
    "    styleImg = input(\"Enter style image path\")\n",
    "    exists(styleImg, \"style path not found!\")\n",
    "    checkpointDir = input(\"Enter checkpointdir path\")\n",
    "    exists(checkpointDir, \"checkpoint dir not found!\")\n",
    "    vggPath = input(\"Enter path to vgg network file\")\n",
    "    exists(vggPath, \"vgg network data not found!\")\n",
    "    trainPath = input(\"Enter path to training images\")\n",
    "    exists(trainPath, \"train path not found!\")\n",
    "    testImg = input(\"Enter path to test images\")\n",
    "    exists(testImg, \"test image not found\")\n",
    "    testResDir = input(\"Enter path to test result directory\")\n",
    "    exists(testResDir, \"test result directory not found\")\n",
    "    contentWeight = input(\"Enter d for default contentWeight\")\n",
    "    if contentWeight == \"d\":\n",
    "        contentWeight = 7.5e0\n",
    "    else:\n",
    "        contentWeight = float(contentWeight)\n",
    "    styleWeight = input(\"Enter d for default styleWeight\")\n",
    "    if styleWeight == \"d\":\n",
    "        styleWeight = 1e2\n",
    "    else:\n",
    "        styleWeight = float(styleWeight)\n",
    "    tvWeight = input(\"Enter d for default tvWeight: \")\n",
    "    if tvWeight == \"d\":\n",
    "        tvWeight = 2e2\n",
    "    else:\n",
    "        tvWeight = float(tvWeight)\n",
    "    learningRate = input(\"Enter d for default learning rate: \")\n",
    "    if learningRate == \"d\":\n",
    "        learningRate = 1e-3\n",
    "    else:\n",
    "        learningRate = float(learningRate)\n",
    "    checkPointIterations = input(\"Enter d for default checkPointIterations: \")\n",
    "    if checkPointIterations == \"d\":\n",
    "        checkPointIterations = 1000\n",
    "    else:\n",
    "        checkPointIterations = int(checkPointIterations)\n",
    "    epochs = input(\"Enter d for default epoch count: \")\n",
    "    if epochs == \"d\":\n",
    "        epochs = 2\n",
    "    else:\n",
    "        epochs = int(epochs)\n",
    "    batch_size = input(\"Enter d for default batch_size: \")\n",
    "    if batch_size == \"d\":\n",
    "        batch_size = 20\n",
    "    else:\n",
    "        batch_size = int(batch_size)\n",
    "    style(styleImg, checkpointDir, vggPath, trainPath, testImg, testResDir, contentWeight, styleWeight, tvWeight, learningRate, checkPointIterations, epochs, batch_size)\n",
    "     \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter style image pathstarry-night.jpg\n",
      "Enter checkpointdir pathcheckpoint1\n",
      "Enter path to vgg network fileimagenet-vgg-verydeep-19.mat\n",
      "Enter path to training imagesdata/images\n",
      "Enter path to test imagesdata/test/COCO_train2014_000000014988.jpg\n",
      "Enter path to test result directorydata/test1\n",
      "Enter d for default contentWeightd\n",
      "Enter d for default styleWeightd\n",
      "Enter d for default tvWeight: d\n",
      "Enter d for default learning rate: d\n",
      "Enter d for default checkPointIterations: d\n",
      "Enter d for default epoch count: d\n",
      "Enter d for default batch_size: d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham.das/.local/lib/python3.5/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has been trimmed slightly..\n",
      "(1, 600, 800, 3)\n",
      "imagenet-vgg-verydeep-19.mat\n",
      "Tensor(\"add_44:0\", shape=(), dtype=float32)\n",
      "UID: 50\n",
      "0\n",
      "assert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham.das/.local/lib/python3.5/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/shubham.das/.local/lib/python3.5/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID: 50, batch time: 27.898560762405396\n",
      "assert\n",
      "UID: 50, batch time: 26.635885000228882\n",
      "1\n",
      "assert\n",
      "UID: 50, batch time: 26.367039442062378\n",
      "assert\n",
      "UID: 50, batch time: 26.210173845291138\n",
      "Epoch 1, Iteration: 2, Loss: 49050156.0\n",
      "style: 39907016.0, content:3820372.0, tv: 5322767.0\n",
      "WARNING:tensorflow:From /home/shubham.das/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoint1/fns.ckpt\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham.das/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "passArgument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
